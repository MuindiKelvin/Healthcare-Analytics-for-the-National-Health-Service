# Summary statistics
summary(data)
# Check for missing values
colSums(is.na(data))
# Visualize the distribution of numerical features
data %>%
gather(key = "Variable", value = "Value", Age:Triglycerides) %>%
ggplot(aes(x = Value)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
facet_wrap(~Variable, scales = "free_x") +
theme_minimal() +
labs(title = "Distribution of Numerical Features")
data$Diabetes <- as.factor(data$Diabetes)
data$Family.History <- as.factor(data$Family.History)
data$Smoking <- as.factor(data$Smoking)
data$Obesity <- as.factor(data$Obesity)
data$Alcohol.Consumption <- as.factor(data$Alcohol.Consumption)
data$Diet <- as.factor(data$Diet)
data$Previous.Heart.Problems <- as.factor(data$Previous.Heart.Problems)
data$Medication.Use <- as.factor(data$Medication.Use)
data$Country <- as.factor(data$Country)
data$Continent <- as.factor(data$Continent)
data$Hemisphere <- as.factor(data$Hemisphere)
data$Heart.Attack.Risk <- as.factor(data$Heart.Attack.Risk)
# Convert "Blood Pressure" to numeric (if represented as a string)
data <- data %>%
mutate(Systolic_BP = as.numeric(str_extract(Blood.Pressure, "^[0-9]+")),
Diastolic_BP = as.numeric(str_extract(Blood.Pressure, "(?<=/)[0-9]+"))) %>%
select(-Blood.Pressure)  # Remove original column
# Normalize numeric features
numeric_cols <- sapply(data, is.numeric)
data[numeric_cols] <- scale(data[numeric_cols])
# Split dataset into training and testing sets
set.seed(123)
train_index <- createDataPartition(data$Heart.Attack.Risk, p = 0.7, list = FALSE)
train_data <- data[train_index,]
test_data <- data[-train_index,]
# Check class distribution before balancing
table(train_data$Heart.Attack.Risk)
# Apply SMOTE to balance the dataset
set.seed(123)
train_data_balanced <- SMOTE(train_data[, -ncol(train_data)],
train_data$Heart.Attack.Risk,
K = 5,
dup_size = 0)$data
# Convert the last column (Heart.Attack.Risk) back to a factor
train_data_balanced$Heart.Attack.Risk <- as.factor(train_data_balanced$class)
# Drop the 'class' column added by SMOTE
train_data_balanced <- train_data_balanced[, -ncol(train_data_balanced)]
# Verify new class distribution
table(train_data_balanced$Heart.Attack.Risk)
View(data)
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(reshape2)
# Read in the data
data <- read.csv("Data/heart_attack_prediction_dataset.csv")
# Summary of the data
summary(data)
# Check for missing values
colSums(is.na(data))
# Distribution of Heart Attack Risk
ggplot(data, aes(x = as.factor(Heart.Attack.Risk))) +
geom_bar(fill = "steelblue") +
labs(title = "Distribution of Heart Attack Risk", x = "Heart Attack Risk", y = "Count")
# Correlation matrix for numeric variables
numeric_vars <- select_if(data, is.numeric)
cor_matrix <- cor(numeric_vars)
melted_cor_matrix <- melt(cor_matrix)
ggplot(melted_cor_matrix, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Correlation Matrix", x = "", y = "")
# Boxplot for Age vs Heart Attack Risk
ggplot(data, aes(x = as.factor(Heart.Attack.Risk), y = Age)) +
geom_boxplot() +
labs(title = "Boxplot of Age vs Heart Attack Risk", x = "Heart Attack Risk", y = "Age")
# Convert categorical variables to factors
data$Sex <- as.factor(data$Sex)
data$Diabetes <- as.factor(data$Diabetes)
data$Family.History <- as.factor(data$Family.History)
data$Smoking <- as.factor(data$Smoking)
data$Obesity <- as.factor(data$Obesity)
data$Alcohol.Consumption <- as.factor(data$Alcohol.Consumption)
data$Previous.Heart.Problems <- as.factor(data$Previous.Heart.Problems)
data$Heart.Attack.Risk <- as.factor(data$Heart.Attack.Risk)
# Feature scaling (normalizing numeric columns)
numeric_vars <- select_if(data, is.numeric)
data[names(numeric_vars)] <- scale(numeric_vars)
# Install and load the 'ROSE' package for class imbalance handling
#install.packages("ROSE")
library(ROSE)
# Handle class imbalance using ROSE (Random Over Sampling Examples)
balanced_data <- ROSE(Heart.Attack.Risk ~ ., data = data, seed = 1)$data
# Check the distribution of Heart Attack Risk after balancing
table(balanced_data$Heart.Attack.Risk)
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(reshape2)
library(corrplot)
# Read in the data
data <- read.csv("Data/heart_attack_prediction_dataset.csv")
# Summary of the data
summary(data)
# Check for missing values
colSums(is.na(data))
# Distribution of Heart Attack Risk
ggplot(data, aes(x = as.factor(Heart.Attack.Risk))) +
geom_bar(fill = "steelblue") +
labs(title = "Distribution of Heart Attack Risk", x = "Heart Attack Risk", y = "Count")
# Correlation matrix for numeric variables
numeric_vars <- select_if(data, is.numeric)
cor_matrix <- cor(numeric_vars)
corrplot(cor_matrix, method = "color", type = "lower", tl.col = "black", tl.srt = 45)
# Boxplot for Age vs Heart Attack Risk
ggplot(data, aes(x = as.factor(Heart.Attack.Risk), y = Age)) +
geom_boxplot() +
labs(title = "Boxplot of Age vs Heart Attack Risk", x = "Heart Attack Risk", y = "Age")
# Convert categorical variables to factors
data$Sex <- as.factor(data$Sex)
data$Diabetes <- as.factor(data$Diabetes)
data$Family.History <- as.factor(data$Family.History)
data$Smoking <- as.factor(data$Smoking)
data$Obesity <- as.factor(data$Obesity)
data$Alcohol.Consumption <- as.factor(data$Alcohol.Consumption)
data$Previous.Heart.Problems <- as.factor(data$Previous.Heart.Problems)
data$Heart.Attack.Risk <- as.factor(data$Heart.Attack.Risk)
# Normalize numeric columns
numeric_vars <- select_if(data, is.numeric)
data[names(numeric_vars)] <- scale(numeric_vars)
# Install and load the 'DMwR' package for SMOTE
# install.packages("DMwR")
library(ROSE)
# Handle class imbalance using SMOTE
balanced_data <- SMOTE(Heart.Attack.Risk ~ ., data = data, perc.over = 200, perc.under = 150)
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(reshape2)
# Read in the data
data <- read.csv("Data/heart_attack_prediction_dataset.csv")
# Summary of the data
summary(data)
# Check for missing values
colSums(is.na(data))
# Distribution of Heart Attack Risk
ggplot(data, aes(x = as.factor(Heart.Attack.Risk))) +
geom_bar(fill = "steelblue") +
labs(title = "Distribution of Heart Attack Risk", x = "Heart Attack Risk", y = "Count")
# Correlation matrix for numeric variables
numeric_vars <- select_if(data, is.numeric)
cor_matrix <- cor(numeric_vars)
melted_cor_matrix <- melt(cor_matrix)
ggplot(melted_cor_matrix, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(title = "Correlation Matrix", x = "", y = "")
# Boxplot for Age vs Heart Attack Risk
ggplot(data, aes(x = as.factor(Heart.Attack.Risk), y = Age)) +
geom_boxplot() +
labs(title = "Boxplot of Age vs Heart Attack Risk", x = "Heart Attack Risk", y = "Age")
# Convert categorical variables to factors
data$Sex <- as.factor(data$Sex)
data$Diabetes <- as.factor(data$Diabetes)
data$Family.History <- as.factor(data$Family.History)
data$Smoking <- as.factor(data$Smoking)
data$Obesity <- as.factor(data$Obesity)
data$Alcohol.Consumption <- as.factor(data$Alcohol.Consumption)
data$Previous.Heart.Problems <- as.factor(data$Previous.Heart.Problems)
data$Heart.Attack.Risk <- as.factor(data$Heart.Attack.Risk)
# Feature scaling (normalizing numeric columns)
numeric_vars <- select_if(data, is.numeric)
data[names(numeric_vars)] <- scale(numeric_vars)
# Load necessary libraries
library(randomForest)
library(caret)
library(ROCR)
library(pROC)
# Set seed for reproducibility
set.seed(123)
# Split the data into training and testing sets (70% train, 30% test)
train_index <- createDataPartition(data$Heart.Attack.Risk, p = 0.7, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Train a Random Forest model
rf_model <- randomForest(Heart.Attack.Risk ~ ., data = train_data, ntree = 500, mtry = 3, importance = TRUE)
# Print the model summary
print(rf_model)
# Predict on the test set
rf_predictions <- predict(rf_model, newdata = test_data, type = "response")
# Confusion matrix
conf_matrix <- confusionMatrix(rf_predictions, test_data$Heart.Attack.Risk)
print(conf_matrix)
# ROC Curve and AUC
rf_probabilities <- predict(rf_model, newdata = test_data, type = "prob")[,2]
roc_curve <- roc(test_data$Heart.Attack.Risk, rf_probabilities, levels = rev(levels(test_data$Heart.Attack.Risk)))
plot(roc_curve, col = "blue", lwd = 2, main = "ROC Curve for Random Forest Model")
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
# Variable importance plot
varImpPlot(rf_model, main = "Variable Importance in the Random Forest Model")
# Feature Importance
importance(rf_model)
# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(caret)
library(corrplot)
library(reshape2)
library(pROC)
# Sampling data
data <- read.csv("Data/heart_attack_prediction_dataset.csv")
# Initial exploration
str(data)  # View structure of the dataset
summary(data)  # Summary statistics
head(data)  # View the first few rows
# Handling Missing Values and Data Types
# Checking for missing values
if (sum(is.na(data)) > 0) {
data <- na.omit(data)  # Remove missing values if they exist
}
# Converting categorical variables to factors
data$Sex <- as.factor(data$Sex)
data$Diabetes <- as.factor(data$Diabetes)
data$Family.History <- as.factor(data$Family.History)
data$Smoking <- as.factor(data$Smoking)
data$Obesity <- as.factor(data$Obesity)
data$Alcohol.Consumption <- as.factor(data$Alcohol.Consumption)
data$Previous.Heart.Problems <- as.factor(data$Previous.Heart.Problems)
data$Medication.Use <- as.factor(data$Medication.Use)
data$Country <- as.factor(data$Country)
data$Continent <- as.factor(data$Continent)
data$Hemisphere <- as.factor(data$Hemisphere)
data$Heart.Attack.Risk <- as.factor(data$Heart.Attack.Risk)
# View updated structure
str(data)
#2.Visualization
# Distribution of Heart Attack Risk
ggplot(data, aes(x = Heart.Attack.Risk)) +
geom_bar(fill = "skyblue") +
theme_minimal() +
ggtitle("Distribution of Heart Attack Risk")
# Age distribution by Heart Attack Risk
ggplot(data, aes(x = Age, fill = Heart.Attack.Risk)) +
geom_histogram(binwidth = 5, position = "dodge") +
theme_minimal() +
ggtitle("Age Distribution by Heart Attack Risk")
# Correlation matrix for numeric variables
numeric_vars <- select_if(data, is.numeric)
cor_matrix <- cor(numeric_vars)
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.8)
#3. Preprocessing
# Scaling numeric features
preprocessParams <- preProcess(numeric_vars, method = c("center", "scale"))
scaled_data <- predict(preprocessParams, numeric_vars)
# Combine with categorical data
final_data <- cbind(scaled_data, select_if(data, is.factor))
# Create training and test sets
set.seed(123)
trainIndex <- createDataPartition(final_data$Heart.Attack.Risk, p = 0.8, list = FALSE)
train_data <- final_data[trainIndex,]
test_data <- final_data[-trainIndex,]
#4.Modeling
#4.1 Logistic Regression
log_model <- glm(Heart.Attack.Risk ~ ., data = train_data, family = binomial)
summary(log_model)
# Predictions
log_predictions <- predict(log_model, test_data, type = "response")
log_predictions <- ifelse(log_predictions > 0.5, 1, 0)
#4.2 Random Forest
library(randomForest)
rf_model <- randomForest(Heart.Attack.Risk ~ ., data = train_data)
print(rf_model)
# Predictions
rf_predictions <- predict(rf_model, test_data)
#4.3 Support Vector Machines (SVM)
library(e1071)
svm_model <- svm(Heart.Attack.Risk ~ ., data = train_data, probability = TRUE)
summary(svm_model)
# Predictions
svm_predictions <- predict(svm_model, test_data)
# Confusion Matrix and Accuracy for Logistic Regression
log_confusion <- confusionMatrix(as.factor(log_predictions), test_data$Heart.Attack.Risk)
log_confusion
# Confusion Matrix and Accuracy for Random Forest
rf_confusion <- confusionMatrix(rf_predictions, test_data$Heart.Attack.Risk)
rf_confusion
# Confusion Matrix and Accuracy for SVM
svm_confusion <- confusionMatrix(svm_predictions, test_data$Heart.Attack.Risk)
svm_confusion
# Function to plot confusion matrix
plot_confusion_matrix <- function(cm, title) {
cm_table <- as.data.frame(cm$table)
ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = 1) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = title, x = "Actual", y = "Predicted")
}
# Confusion Matrix for Logistic Regression
log_confusion <- confusionMatrix(as.factor(log_predictions), test_data$Heart.Attack.Risk)
log_cm_plot <- plot_confusion_matrix(log_confusion, "Logistic Regression Confusion Matrix")
# Confusion Matrix for Random Forest
rf_confusion <- confusionMatrix(rf_predictions, test_data$Heart.Attack.Risk)
rf_cm_plot <- plot_confusion_matrix(rf_confusion, "Random Forest Confusion Matrix")
# Confusion Matrix for SVM
svm_confusion <- confusionMatrix(svm_predictions, test_data$Heart.Attack.Risk)
svm_cm_plot <- plot_confusion_matrix(svm_confusion, "SVM Confusion Matrix")
# Display the plots
print(log_cm_plot)
print(rf_cm_plot)
print(svm_cm_plot)
# Function to calculate and return evaluation metrics
evaluate_model <- function(confusion) {
accuracy <- confusion$overall['Accuracy']
precision <- confusion$byClass['Pos Pred Value']
recall <- confusion$byClass['Sensitivity']
f1 <- 2 * ((precision * recall) / (precision + recall))
metrics <- c(accuracy, precision, recall, f1)
names(metrics) <- c("Accuracy", "Precision", "Recall", "F1 Score")
return(metrics)
}
# Evaluate Logistic Regression
log_metrics <- evaluate_model(log_confusion)
# Evaluate Random Forest
rf_metrics <- evaluate_model(rf_confusion)
# Evaluate SVM
svm_metrics <- evaluate_model(svm_confusion)
# Combine metrics into a single data frame
evaluation_results <- data.frame(
Metric = c("Accuracy", "Precision", "Recall", "F1 Score"),
Logistic_Regression = log_metrics,
Random_Forest = rf_metrics,
SVM = svm_metrics
)
print(evaluation_results)
# Calculate AUC for Logistic Regression
log_roc <- roc(test_data$Heart.Attack.Risk, as.numeric(log_predictions))
log_auc <- auc(log_roc)
# Calculate AUC for Random Forest
rf_roc <- roc(test_data$Heart.Attack.Risk, as.numeric(rf_predictions))
rf_auc <- auc(rf_roc)
# Calculate AUC for SVM
svm_roc <- roc(test_data$Heart.Attack.Risk, as.numeric(svm_predictions))
svm_auc <- auc(svm_roc)
# Add AUC to the evaluation results
evaluation_results <- rbind(evaluation_results,
AUC = c(Logistic_Regression = log_auc,
Random_Forest = rf_auc,
SVM = svm_auc))
print(evaluation_results)
# Save the pre-processing parameters and the Random Forest model
saveRDS(preprocessParams, "preprocess_params.rds")
saveRDS(rf_model, "random_forest_model.rds")
library(shiny); runApp('Healthcare_Analytics_App.R')
# Load necessary libraries
library(tidyverse)
library(ggplot2)
library(caret)
library(corrplot)
library(reshape2)
library(pROC)
# Sampling data
data <- read.csv("Data/heart_attack_prediction_dataset.csv")
# Initial exploration
str(data)  # View structure of the dataset
summary(data)  # Summary statistics
head(data)  # View the first few rows
# Handling Missing Values and Data Types
# Checking for missing values
if (sum(is.na(data)) > 0) {
data <- na.omit(data)  # Remove missing values if they exist
}
# Converting categorical variables to factors
data$Sex <- as.factor(data$Sex)
data$Diabetes <- as.factor(data$Diabetes)
data$Family.History <- as.factor(data$Family.History)
data$Smoking <- as.factor(data$Smoking)
data$Obesity <- as.factor(data$Obesity)
data$Alcohol.Consumption <- as.factor(data$Alcohol.Consumption)
data$Previous.Heart.Problems <- as.factor(data$Previous.Heart.Problems)
data$Medication.Use <- as.factor(data$Medication.Use)
data$Country <- as.factor(data$Country)
data$Continent <- as.factor(data$Continent)
data$Hemisphere <- as.factor(data$Hemisphere)
data$Heart.Attack.Risk <- as.factor(data$Heart.Attack.Risk)
# View updated structure
str(data)
#2.Visualization
# Distribution of Heart Attack Risk
ggplot(data, aes(x = Heart.Attack.Risk)) +
geom_bar(fill = "skyblue") +
theme_minimal() +
ggtitle("Distribution of Heart Attack Risk")
# Age distribution by Heart Attack Risk
ggplot(data, aes(x = Age, fill = Heart.Attack.Risk)) +
geom_histogram(binwidth = 5, position = "dodge") +
theme_minimal() +
ggtitle("Age Distribution by Heart Attack Risk")
# Correlation matrix for numeric variables
numeric_vars <- select_if(data, is.numeric)
cor_matrix <- cor(numeric_vars)
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.8)
#3. Preprocessing
# Scaling numeric features
preprocessParams <- preProcess(numeric_vars, method = c("center", "scale"))
scaled_data <- predict(preprocessParams, numeric_vars)
# Combine with categorical data
final_data <- cbind(scaled_data, select_if(data, is.factor))
# Create training and test sets
set.seed(123)
trainIndex <- createDataPartition(final_data$Heart.Attack.Risk, p = 0.8, list = FALSE)
train_data <- final_data[trainIndex,]
test_data <- final_data[-trainIndex,]
#4.Modeling
#4.1 Logistic Regression
log_model <- glm(Heart.Attack.Risk ~ ., data = train_data, family = binomial)
summary(log_model)
# Predictions
log_predictions <- predict(log_model, test_data, type = "response")
log_predictions <- ifelse(log_predictions > 0.5, 1, 0)
#4.2 Random Forest
library(randomForest)
rf_model <- randomForest(Heart.Attack.Risk ~ ., data = train_data)
print(rf_model)
# Predictions
rf_predictions <- predict(rf_model, test_data)
#4.3 Support Vector Machines (SVM)
library(e1071)
svm_model <- svm(Heart.Attack.Risk ~ ., data = train_data, probability = TRUE)
summary(svm_model)
# Predictions
svm_predictions <- predict(svm_model, test_data)
# Confusion Matrix and Accuracy for Logistic Regression
log_confusion <- confusionMatrix(as.factor(log_predictions), test_data$Heart.Attack.Risk)
log_confusion
# Confusion Matrix and Accuracy for Random Forest
rf_confusion <- confusionMatrix(rf_predictions, test_data$Heart.Attack.Risk)
rf_confusion
# Confusion Matrix and Accuracy for SVM
svm_confusion <- confusionMatrix(svm_predictions, test_data$Heart.Attack.Risk)
svm_confusion
# Function to plot confusion matrix
plot_confusion_matrix <- function(cm, title) {
cm_table <- as.data.frame(cm$table)
ggplot(data = cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = 1) +
scale_fill_gradient(low = "white", high = "steelblue") +
theme_minimal() +
labs(title = title, x = "Actual", y = "Predicted")
}
# Confusion Matrix for Logistic Regression
log_confusion <- confusionMatrix(as.factor(log_predictions), test_data$Heart.Attack.Risk)
log_cm_plot <- plot_confusion_matrix(log_confusion, "Logistic Regression Confusion Matrix")
# Confusion Matrix for Random Forest
rf_confusion <- confusionMatrix(rf_predictions, test_data$Heart.Attack.Risk)
rf_cm_plot <- plot_confusion_matrix(rf_confusion, "Random Forest Confusion Matrix")
# Confusion Matrix for SVM
svm_confusion <- confusionMatrix(svm_predictions, test_data$Heart.Attack.Risk)
svm_cm_plot <- plot_confusion_matrix(svm_confusion, "SVM Confusion Matrix")
# Display the plots
print(log_cm_plot)
print(rf_cm_plot)
print(svm_cm_plot)
# Function to calculate and return evaluation metrics
evaluate_model <- function(confusion) {
accuracy <- confusion$overall['Accuracy']
precision <- confusion$byClass['Pos Pred Value']
recall <- confusion$byClass['Sensitivity']
f1 <- 2 * ((precision * recall) / (precision + recall))
metrics <- c(accuracy, precision, recall, f1)
names(metrics) <- c("Accuracy", "Precision", "Recall", "F1 Score")
return(metrics)
}
# Evaluate Logistic Regression
log_metrics <- evaluate_model(log_confusion)
# Evaluate Random Forest
rf_metrics <- evaluate_model(rf_confusion)
# Evaluate SVM
svm_metrics <- evaluate_model(svm_confusion)
# Combine metrics into a single data frame
evaluation_results <- data.frame(
Metric = c("Accuracy", "Precision", "Recall", "F1 Score"),
Logistic_Regression = log_metrics,
Random_Forest = rf_metrics,
SVM = svm_metrics
)
print(evaluation_results)
# Calculate AUC for Logistic Regression
log_roc <- roc(test_data$Heart.Attack.Risk, as.numeric(log_predictions))
log_auc <- auc(log_roc)
# Calculate AUC for Random Forest
rf_roc <- roc(test_data$Heart.Attack.Risk, as.numeric(rf_predictions))
rf_auc <- auc(rf_roc)
# Calculate AUC for SVM
svm_roc <- roc(test_data$Heart.Attack.Risk, as.numeric(svm_predictions))
svm_auc <- auc(svm_roc)
# Add AUC to the evaluation results
evaluation_results <- rbind(evaluation_results,
AUC = c(Logistic_Regression = log_auc,
Random_Forest = rf_auc,
SVM = svm_auc))
print(evaluation_results)
# Save the pre-processing parameters and the Random Forest model
saveRDS(preprocessParams, "preprocess_params.rds")
saveRDS(rf_model, "random_forest_model.rds")
